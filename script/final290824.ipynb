{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb51e4c1-f198-457f-bcfb-0db2a4970eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from sklearn.cluster import DBSCAN\n",
    "import hicstraw\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca6bc228-e629-457c-8bf5-012d75f2862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and filte interchroms interactions\n",
    "def read_and_filter_data(merged_nodups_file):\n",
    "\n",
    "    columns = ['str1','chr1', 'pos1', 'frag1', 'str2', 'chr2', 'pos2', \n",
    "               'frag2', 'mapq1', 'cigar1', 'sequence1', 'mapq2', \n",
    "               'cigar2', 'sequence2', 'readname1', 'readname2']\n",
    "    \n",
    "    # Open and read the gzip file\n",
    "    with gzip.open(merged_nodups_file, 'rt') as f:\n",
    "        data = pd.read_csv(f, delimiter=' ', header=None, names=columns, index_col=False)\n",
    "        data = data[data['chr1'] != data['chr2']].copy()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6b4ac4-de5a-4ddd-87dd-f9105b747d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hic_file(merged_nodups_file, suffix='inter_30.hic'):\n",
    "    base_name = os.path.basename(merged_nodups_file)  \n",
    "    prefix = '_'.join(base_name.split('_')[:3])  \n",
    "\n",
    "    parent_dir = os.path.dirname(os.path.dirname(merged_nodups_file))\n",
    "    hic_file = os.path.join(parent_dir, 'hic', f'{prefix}_{suffix}')\n",
    "    \n",
    "    return hic_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f970559f-7d3e-4aca-98ce-8bdad623753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract chrom lengths\n",
    "def extract_chromosome_lengths(file_path):\n",
    "    chromosome_lengths = {}\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):  # Skip comments\n",
    "                continue\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) >= 9:\n",
    "                chr_name = fields[9]  # UCSC-style name (chr1, chr2, etc.)\n",
    "                chr_length = int(fields[8])  # Sequence-Length\n",
    "                chromosome_lengths[chr_name] = chr_length\n",
    "    \n",
    "    return chromosome_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44aff35e-8840-4b6b-a145-920ad7446c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_genomeV_and_extract_chrom_dict(hicfile_path, t2t_path):\n",
    "    hic = hicstraw.HiCFile(os.path.join(hicfile_path))\n",
    "    genome_id = hic.getGenomeID().split('/')[-1]\n",
    "    if genome_id == \"hg19_canonical.chrom.sizes\":\n",
    "        chrom_file = os.path.join(os.path.dirname(hicfile_path), '../genome/male.hg19.chrom.sizes')\n",
    "        chrom_dict = {}\n",
    "        try:\n",
    "            with open(chrom_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    chrom_name, chrom_size = line.strip().split('\\t')\n",
    "                    chrom_dict[chrom_name] = int(chrom_size)\n",
    "            return chrom_dict\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Chromosome size file not found at {chrom_file}\")\n",
    "            return None\n",
    "        \n",
    "    elif genome_id == \"hgT2T.chromsizes\":\n",
    "        return extract_chromosome_lengths(t2t_path)\n",
    "    \n",
    "    else:\n",
    "        print(\"Error: Genome version chrom size file doesn't exist\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10725a46-57a8-4968-9fc5-2328cf9c5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bin df with bin coordinates and chrrom names\n",
    "def create_bins(data, binsize, chromosome_lengths):\n",
    "\n",
    "    bins = []\n",
    "    bin_index = 0\n",
    "    \n",
    "    for chrom, chrom_length in chromosome_lengths.items():\n",
    "        # Reset bin_start for each chromosome\n",
    "        bin_start = 1\n",
    "        while bin_start <= chrom_length:\n",
    "            bin_end = min(bin_start + binsize - 1, chrom_length)\n",
    "            bins.append((chrom, bin_start, bin_end, bin_index))\n",
    "            bin_start = bin_end + 1\n",
    "            bin_index += 1\n",
    "    \n",
    "    # Convert bins to a DataFrame\n",
    "    bins_df = pd.DataFrame(bins, columns=['chrom', 'bin_start', 'bin_end', 'bin_index'])\n",
    "    \n",
    "    return bins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ff90e3-a300-4464-9ead-6543a95f36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bin indexes to df with all information\n",
    "def assign_bins_to_interactions(data, bins_df):\n",
    "    # Create a dictionary for fast lookup of bin indexes based on chromosome and position\n",
    "    bins_dict = {}\n",
    "    \n",
    "    for _, row in bins_df.iterrows():\n",
    "        chrom = row['chrom']\n",
    "        bin_start = row['bin_start']\n",
    "        bin_end = row['bin_end']\n",
    "        bin_index = row['bin_index']\n",
    "        \n",
    "        if chrom not in bins_dict:\n",
    "            bins_dict[chrom] = []\n",
    "        bins_dict[chrom].append((bin_start, bin_end, bin_index))\n",
    "    \n",
    "    def find_bin_index(chrom, pos):\n",
    "        if chrom in bins_dict:\n",
    "            for bin_start, bin_end, bin_index in bins_dict[chrom]:\n",
    "                if bin_start <= pos <= bin_end:\n",
    "                    return int(bin_index)\n",
    "        return -1\n",
    "\n",
    "    data['bin1_index'] = data.apply(lambda row: find_bin_index(row['chr1'], row['pos1']), axis=1)\n",
    "    data['bin2_index'] = data.apply(lambda row: find_bin_index(row['chr2'], row['pos2']), axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a5b32c-5ebe-439b-b2f4-4d20bbba780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_symmetric_matrix(bin_df, data_with_bins):\n",
    "    # Initialize an empty square matrix of size len(bin_df) x len(bin_df)\n",
    "    matrix_size = len(bin_df) \n",
    "    symmetric_matrix = np.zeros((matrix_size, matrix_size), dtype=int)\n",
    "\n",
    "    # Iterate over the data_with_bins to populate the symmetric matrix\n",
    "    for _, row in data_with_bins.iterrows():\n",
    "        bin1 = row['bin1_index']\n",
    "        bin2 = row['bin2_index']\n",
    "        \n",
    "        # Add the value to both (bin1, bin2) and (bin2, bin1) to ensure symmetry\n",
    "        symmetric_matrix[bin1, bin2] += 1\n",
    "        symmetric_matrix[bin2, bin1] += 1\n",
    "    \n",
    "    # Convert the numpy array to a DataFrame for better readability\n",
    "    symmetric_matrix_df = pd.DataFrame(symmetric_matrix, index=bin_df['bin_index'], columns=bin_df['bin_index'])\n",
    "    symmetric_matrix_df.index.name = 'bin1_index'\n",
    "    symmetric_matrix_df.columns.name = 'bin2_index'\n",
    "    \n",
    "    return symmetric_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e13a44-73b9-4707-ace2-d4f5cdf02691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_contact_matrix(contact_matrix, bins_df, chromosome_lengths):\n",
    "    bin_to_chrom = bins_df.set_index('bin_index')['chrom'].to_dict()\n",
    "    \n",
    "    df_long = contact_matrix.stack().reset_index()\n",
    "    df_long.columns = ['bin1_index', 'bin2_index', 'value']\n",
    "\n",
    "    df_long['chrom1'] = df_long['bin1_index'].map(bin_to_chrom)\n",
    "    df_long['chrom2'] = df_long['bin2_index'].map(bin_to_chrom)\n",
    "    \n",
    "    df_long['normalization_factor'] = df_long['chrom1'].map(chromosome_lengths) * df_long['chrom2'].map(chromosome_lengths)\n",
    "    df_long['normalized_value'] = df_long['value'] / df_long['normalization_factor']\n",
    "\n",
    "    df_long = df_long.drop(columns=['value', 'chrom1', 'chrom2', 'normalization_factor'])\n",
    "\n",
    "    df_long = df_long.groupby(['bin1_index', 'bin2_index'])['normalized_value'].mean().reset_index()\n",
    "\n",
    "    try:\n",
    "        normalized_matrix = df_long.pivot(index='bin1_index', columns='bin2_index', values='normalized_value').fillna(0)\n",
    "    except Exception as e:\n",
    "        print(\"Error converting to pivot:\", str(e))\n",
    "        return df_long  # Возвращаем в длинном формате, если ошибка\n",
    "\n",
    "    # Устанавливаем правильные имена индексов и столбцов\n",
    "    normalized_matrix.index.name = 'bin1_index'\n",
    "    normalized_matrix.columns.name = 'bin2_index'\n",
    "\n",
    "    normalized_matrix.index.name = 'bin1_index'\n",
    "    normalized_matrix.columns.name = 'bin2_index'\n",
    "    \n",
    "    return normalized_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078ec1bc-0eae-4792-abdd-380c364c5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster windows with high values\n",
    "def cluster_and_select_best_region(coords_list, eps=1.5, min_samples=2):\n",
    "\n",
    "    if len(coords_list) == 0:\n",
    "        return []\n",
    "\n",
    "    # Convert list of coordinates to numpy array\n",
    "    coords_array = np.array(coords_list)\n",
    "    \n",
    "    # Apply DBSCAN clustering\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(coords_array)\n",
    "    \n",
    "    # Cluster labels (-1 is for noise)\n",
    "    labels = clustering.labels_\n",
    "    \n",
    "    # Initialize a list to store the best region from each cluster\n",
    "    best_regions = []\n",
    "    \n",
    "    # Iterate over unique clusters\n",
    "    for label in set(labels):\n",
    "        if label == -1:\n",
    "            continue  # Skip noise points\n",
    "        \n",
    "        # Get indices of regions in this cluster\n",
    "        cluster_indices = np.where(labels == label)[0]\n",
    "        cluster_coords = [coords_list[i] for i in cluster_indices]\n",
    "        \n",
    "        # Determine the \"best\" region in the cluster (by max sum)\n",
    "        best_coords = cluster_coords[0]  # Placeholder, you can improve selection criteria\n",
    "        best_regions.append(best_coords)\n",
    "    \n",
    "    return best_regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b2af47-dcc9-4e82-b106-466960cfe0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect translocation regions\n",
    "def find_top_balanced_high_contact_regions(matrix, region_size=10, threshold=20, tolerance=0.1):\n",
    "    region_sums = []\n",
    "    visited_coords = set()  \n",
    "    \n",
    "    for i in range(matrix.shape[0] - region_size + 1):\n",
    "        for j in range(matrix.shape[1] - region_size + 1):\n",
    "            if (i, j) in visited_coords or (j, i) in visited_coords:\n",
    "                continue\n",
    "            \n",
    "            region = matrix[i:i+region_size, j:j+region_size]\n",
    "            region_filtered = region * (region > threshold)\n",
    "            \n",
    "            row_sums = np.sum(region_filtered, axis=1)\n",
    "            col_sums = np.sum(region_filtered, axis=0)\n",
    "            \n",
    "            row_sum_mean = np.mean(row_sums)\n",
    "            col_sum_mean = np.mean(col_sums)\n",
    "            \n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                if np.all(np.abs(row_sums - row_sum_mean) / row_sum_mean < tolerance) and \\\n",
    "                   np.all(np.abs(col_sums - col_sum_mean) / col_sum_mean < tolerance):\n",
    "                    region_sum = np.sum(region_filtered)\n",
    "                    region_sums.append(((i, j), region_sum, region))\n",
    "                \n",
    "                visited_coords.add((i, j))\n",
    "                visited_coords.add((j, i))\n",
    "    \n",
    "    top_regions = sorted(region_sums, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Cluster and select the best region\n",
    "    cluster_coords = cluster_and_select_best_region([coords for coords, region_sum, region in top_regions], eps=2, min_samples=5)\n",
    "    \n",
    "    # Map the clusters to top regions\n",
    "    top_regions_filtered = [region for region in top_regions if region[0] in cluster_coords]\n",
    "\n",
    "    return [(coords, region_sum) for coords, region_sum, region in top_regions_filtered]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f07b198-7442-40ea-beee-e8ff35f52ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_true_regions(region_list, threshold_factor=2, percentile=90):\n",
    "    if not region_list:\n",
    "        return []\n",
    "    \n",
    "    region_sums = np.array([sum_val for _, sum_val in region_list])\n",
    "    mean_val = np.mean(region_sums)\n",
    "    std_dev = np.std(region_sums)\n",
    "    \n",
    "    # Адаптивный threshold_factor на основе размера выборки\n",
    "    if len(region_sums) > 50:\n",
    "        threshold_factor = max(threshold_factor, np.log10(len(region_sums)))\n",
    "    \n",
    "    potential_true_regions = []\n",
    "    for i in range(len(region_sums)):\n",
    "        sum_val = region_sums[i]\n",
    "        if sum_val > mean_val + threshold_factor * std_dev:\n",
    "            if i > 0:\n",
    "                previous_sum = region_sums[i-1]\n",
    "                difference = abs(previous_sum - sum_val)\n",
    "                if difference / previous_sum < 0.1:  # Пример порога для резкой ступени\n",
    "                    potential_true_regions.append((region_list[i][0], sum_val))\n",
    "            else:\n",
    "                potential_true_regions.append((region_list[i][0], sum_val))\n",
    "    \n",
    "    if not potential_true_regions:\n",
    "        return [(region, sum_val, False) for region, sum_val in region_list]\n",
    "    \n",
    "    percentile_value = np.percentile(region_sums, percentile)\n",
    "    \n",
    "    true_regions = [(region, sum_val) for region, sum_val in potential_true_regions if sum_val >= percentile_value]\n",
    "    true_regions_set = set([region for region, _ in true_regions])\n",
    "    \n",
    "    marked_regions = []\n",
    "    false_found = False\n",
    "    \n",
    "    for region, sum_val in region_list:\n",
    "        if region in true_regions_set and not false_found:\n",
    "            marked_regions.append((region, sum_val, True))\n",
    "        else:\n",
    "            marked_regions.append((region, sum_val, False))\n",
    "            false_found = True  # После первого False все последующие значения будут False\n",
    "    \n",
    "    return marked_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6cdf51d-8f6d-441a-b96b-3f069fb592b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_coords_to_chromosome(coords_list, bin1_df):\n",
    "\n",
    "    mapped_results = []\n",
    "    \n",
    "    for coords, region_sum, b in coords_list:\n",
    "        chrom1 = bin1_df.loc[bin1_df['bin_index'] == coords[0], 'chrom'].values[0]\n",
    "        chrom2 = bin1_df.loc[bin1_df['bin_index'] == coords[1], 'chrom'].values[0]\n",
    "        if chrom1 != chrom2:\n",
    "            mapped_results.append(((chrom1, chrom2), region_sum, b))\n",
    "    \n",
    "    return mapped_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c046652-c9f7-46b7-9173-b39f81679e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_true_rearrangements(file_path):\n",
    "    true_rearrangements = set()\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        next(file)\n",
    "        \n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            chr1 = parts[1]\n",
    "            chr2 = parts[4]\n",
    "            true_rearrangements.add((chr1, chr2))\n",
    "    \n",
    "    return true_rearrangements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "479c13b2-bf75-45fc-a5a9-589a3059df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tpr_fpr(predictions, true_rearrangements):\n",
    "    if len(predictions) == 0:\n",
    "        print(\"No predictions found. Skipping TPR and FPR calculation.\")\n",
    "        return None, None\n",
    "\n",
    "    TP = 0 \n",
    "    FP = 0  \n",
    "\n",
    "    for prediction in predictions:\n",
    "        chromosome_pair, score, is_true = prediction\n",
    "        \n",
    "        if is_true:\n",
    "            if chromosome_pair in true_rearrangements:\n",
    "                TP += 1  \n",
    "            else:\n",
    "                FP += 1  \n",
    "                \n",
    "    TPR = TP / (TP + FP) if (TP + FP) > 0 else 0  \n",
    "    FPR = FP / len(predictions)  \n",
    "\n",
    "    return TPR, FPR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f6ec0f0-6c51-46d9-bdb3-3136aadc44d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: IlI_K3_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: HAN_K5_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.07\n",
      "-------------------------------\n",
      "Sample: Kaz3_K_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.05\n",
      "-------------------------------\n",
      "Sample: Fuks2_K1_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Kira1_K1_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Pash_e2_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Vla1_e_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 1.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: BTR_e3_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Boc_e4_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: CHR_e1_Torgasheva_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "Sample: YAK_e4_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: XAH_K13_Torgasheva_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Kra_e_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.06\n",
      "-------------------------------\n",
      "Sample: 11425_K_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.03\n",
      "-------------------------------\n",
      "Sample: Kul_K_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.09\n",
      "-------------------------------\n",
      "Sample: Shen3_e_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.04\n",
      "-------------------------------\n",
      "Sample: MAD_e3_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Gri2_e_MGNC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.03\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: Mel6_K_Moscow_merged_nodups.txt.gz, skipping this sample.\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: YAkK_e6_Moscow_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: Mat2_K_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: Ton1_K_Moscow_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: Pash_e3_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "Sample: Ton1_K_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: Bal1_K_Sirius_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: Aks1_K_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "Sample: Sheg1_e_MGNC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.03\n",
      "-------------------------------\n",
      "Sample: MAD_e3_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.17\n",
      "-------------------------------\n",
      "Sample: Kaz3_K_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: HAN_e5_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Fed3_K_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.02\n",
      "-------------------------------\n",
      "Sample: IlI_e4_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.02\n",
      "-------------------------------\n",
      "Sample: BTR_e9_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.07\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: Shen2_e_BGI_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: Pash_e3_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Pash_K2_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "Sample: Mog1_e_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: Kul_K_Sirius_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: Pash_K3_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 1.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: IlI_K3_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "Sample: Shen1_K_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Sach2_K_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.06\n",
      "-------------------------------\n",
      "Sample: Bal1_K_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Zap_e2_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.50\n",
      "False Positive Rate (FPR): 0.11\n",
      "-------------------------------\n",
      "Sample: Boc_K4_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.02\n",
      "-------------------------------\n",
      "Sample: MAD_K3_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.06\n",
      "False Positive Rate (FPR): 0.04\n",
      "-------------------------------\n",
      "Sample: Kond5_K_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: Pash_e2_ENC_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: BOC_K1_Sirius_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.03\n",
      "-------------------------------\n",
      "Sample: Zap_K2_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 1.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: XAH_e13_Torgasheva_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 1.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Zap_e3_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 1.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: Shen3_e_BGI_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: CHR_K1_Torgasheva_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "Sample: BTR_e3_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Ore1_K_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: HAN_e5_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.03\n",
      "-------------------------------\n",
      "Sample: Kov1_e_MGNC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Sach2_K_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.06\n",
      "-------------------------------\n",
      "Sample: BOC_K1_Torgasheva_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.02\n",
      "-------------------------------\n",
      "Sample: Ore1_K_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Kul2_K_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Mel6_K_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.02\n",
      "-------------------------------\n",
      "Sample: Pash_K2_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.17\n",
      "-------------------------------\n",
      "Sample: YAK_e4_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.08\n",
      "-------------------------------\n",
      "Sample: XAH_e13_Sirius_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 1.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: Kra_e_BGI_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: BOC_e1_Sirius_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.06\n",
      "-------------------------------\n",
      "Sample: Kur3_e_MGNC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.05\n",
      "-------------------------------\n",
      "Sample: IlI_e4_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "Sample: Bal3_e_MGNC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: Fed3_K_Sirius_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: CHR_e1_Sirius_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.12\n",
      "-------------------------------\n",
      "Sample: CHR_K1_Sirius_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.02\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: Aks1_K_Sirius_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: HAN_K5_Moscow_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.02\n",
      "-------------------------------\n",
      "Sample: Pash_K3_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 1.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: Vla2_e_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "Sample: Fuks1_K_ENC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "Sample: Kaz1_e_MGNC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "No predictions found. Skipping TPR and FPR calculation.\n",
      "No potential regions found for sample: BTR_e9_ENC_merged_nodups.txt.gz, skipping this sample.\n",
      "Sample: Shen1_K_MGNC_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.02\n",
      "-------------------------------\n",
      "Sample: XAH_K13_Sirius_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.50\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: MAD_K3_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.04\n",
      "-------------------------------\n",
      "Sample: Mat2_K_BGI_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.00\n",
      "-------------------------------\n",
      "Sample: BOC_e1_Torgasheva_merged_nodups.txt.gz\n",
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.01\n",
      "-------------------------------\n",
      "Average True Positive Rate (TPR) across all samples: 0.11\n",
      "Average False Positive Rate (FPR) across all samples: 0.02\n"
     ]
    }
   ],
   "source": [
    "merged_nodups_dir = '/media/eternus1/nfs/projects/dpanchenko/test_embrio/data/merged_nodups/'\n",
    "chrom_len_t2t = '/media/eternus1/nfs/projects/dpanchenko/test_embrio/data/genome/GCF_009914755.1_T2T-CHM13v2.0_assembly_report.txt'\n",
    "true_rearrangements_file = '/media/eternus1/nfs/projects/dpanchenko/test_embrio/data/genome/translocations.txt'\n",
    "\n",
    "# Считываем истинные перестройки\n",
    "true_rearrangements = read_true_rearrangements(true_rearrangements_file)\n",
    "\n",
    "# Инициализация переменных для накопления показателей TPR и FPR\n",
    "total_TPR = 0\n",
    "total_FPR = 0\n",
    "sample_count = 0\n",
    "\n",
    "# Проход по всем файлам в директории\n",
    "for filename in os.listdir(merged_nodups_dir):\n",
    "    if filename.endswith('_merged_nodups.txt.gz'):\n",
    "        merged_nodups_file = os.path.join(merged_nodups_dir, filename)\n",
    "        \n",
    "        hic_file = get_hic_file(merged_nodups_file)\n",
    "        chromosome_lengths = check_genomeV_and_extract_chrom_dict(hic_file, chrom_len_t2t)\n",
    "        data = read_and_filter_data(merged_nodups_file)\n",
    "        \n",
    "        binsize = 5000000\n",
    "        bins_df = create_bins(data, binsize, chromosome_lengths)\n",
    "        data_with_bins = assign_bins_to_interactions(data, bins_df)\n",
    "        \n",
    "        contact_matrix = create_symmetric_matrix(bins_df, data_with_bins)\n",
    "        top_balanced_regions = find_top_balanced_high_contact_regions(contact_matrix.values, region_size=10, threshold=0, tolerance=0.99)\n",
    "        \n",
    "        true_regions = filter_true_regions([(coords, region_sum) for coords, region_sum in top_balanced_regions], threshold_factor=2, percentile=90)\n",
    "        mapped_chromosomes = map_coords_to_chromosome(true_regions, bins_df)\n",
    "        \n",
    "        # Проверка на нулевые значения в mapped_chromosomes\n",
    "        TPR, FPR = calculate_tpr_fpr(mapped_chromosomes, true_rearrangements)\n",
    "        \n",
    "        if TPR is None or FPR is None:\n",
    "            print(f\"No potential regions found for sample: {filename}, skipping this sample.\")\n",
    "            continue\n",
    "        \n",
    "        # Проверяем, что значения TPR и FPR не равны None перед выводом\n",
    "        print(f\"Sample: {filename}\")\n",
    "        if TPR is not None:\n",
    "            print(f\"True Positive Rate (TPR): {TPR:.2f}\")\n",
    "        if FPR is not None:\n",
    "            print(f\"False Positive Rate (FPR): {FPR:.2f}\")\n",
    "        print(\"-------------------------------\")\n",
    "        \n",
    "        # Накопление показателей\n",
    "        total_TPR += TPR\n",
    "        total_FPR += FPR\n",
    "        sample_count += 1\n",
    "\n",
    "# Вывод средних значений TPR и FPR по всем образцам\n",
    "if sample_count > 0:\n",
    "    average_TPR = total_TPR / sample_count\n",
    "    average_FPR = total_FPR / sample_count\n",
    "    print(f\"Average True Positive Rate (TPR) across all samples: {average_TPR:.2f}\")\n",
    "    print(f\"Average False Positive Rate (FPR) across all samples: {average_FPR:.2f}\")\n",
    "else:\n",
    "    print(\"No valid samples found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945cb6e-a48c-44b7-b351-9d4bad9d54dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
